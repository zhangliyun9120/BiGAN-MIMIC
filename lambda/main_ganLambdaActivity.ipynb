{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from bgan_i_ganLambda.ipynb\n",
      "importing Jupyter notebook from ugan_i_ganLambda.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random \n",
    "import torch as T\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import DataLoader, Dataset, ConcatDataset, IterableDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import math\n",
    "import argparse\n",
    "import import_ipynb\n",
    "from bgan_i_ganLambda import *\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "save_path = \"data/saved_models/ganWganLambda.tar\"#vaegan_model - Copy.tar\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "if not os.path.exists(\"data/saved_models\"):\n",
    "    os.makedirs(\"data/saved_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--eval'], dest='eval', nargs=None, const=None, default=True, type=None, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ARG_PARSER = ArgumentParser()\n",
    "\n",
    "ARG_PARSER.add_argument('--nfeatures', default=609, type=int)\n",
    "ARG_PARSER.add_argument('--dfeatures', default=43, type=int)\n",
    "ARG_PARSER.add_argument('--ehidden', default=300, type=int)\n",
    "ARG_PARSER.add_argument('--model', type=str)\n",
    "\n",
    "ARG_PARSER.add_argument('--air', default=True)\n",
    "ARG_PARSER.add_argument('--mimic', default=False)\n",
    "\n",
    "ARG_PARSER.add_argument('--num_epochs', default=200, type=int)\n",
    "ARG_PARSER.add_argument('--seq_len', default=20, type=int)\n",
    "ARG_PARSER.add_argument('--pred_len', default=8, type=int)\n",
    "ARG_PARSER.add_argument('--missingRate', default=10, type=int)\n",
    "ARG_PARSER.add_argument('--patience', default=200, type=int)\n",
    "ARG_PARSER.add_argument('--e_lrn_rate', default=0.1, type=float)\n",
    "ARG_PARSER.add_argument('--g_lrn_rate', default=0.1, type=float)\n",
    "ARG_PARSER.add_argument('--d_lrn_rate', default=0.001, type=float)\n",
    "ARG_PARSER.add_argument('--resume_training', default=False)\n",
    "ARG_PARSER.add_argument('--train', default=False)\n",
    "ARG_PARSER.add_argument('--evalImp', default=True)\n",
    "ARG_PARSER.add_argument('--evalPred', default=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARGS = ARG_PARSER.parse_args(args=[])\n",
    "MAX_SEQ_LEN = ARGS.seq_len\n",
    "BATCH_SIZE = ARGS.batch_size\n",
    "EPSILON = 1e-40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf#11.1179\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model, discriminator, optimizer, optimizer_d, save_path):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, discriminator, optimizer, optimizer_d, save_path)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, discriminator, optimizer, optimizer_d, save_path)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model, discriminator, optimizer, optimizer_d, save_path):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        T.save({\n",
    "            \"model\": model.state_dict(),\n",
    "            'trainer': optimizer.state_dict(),\n",
    "            \"discriminator\": discriminator.state_dict(),\n",
    "            'trainer_d': optimizer_d.state_dict()\n",
    "        }, save_path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pred_test(args, model,discriminator,predWin):\n",
    "    model.eval()\n",
    "    \n",
    "    RLoss=0\n",
    "    FLoss=0\n",
    "    mseLoss=0\n",
    "    mseLossF=0\n",
    "    TBatches=0\n",
    "    oBmi=[]\n",
    "    oBmiF=[]\n",
    "    iBmi=[]\n",
    "    oAge=[]\n",
    "    oSex=[]\n",
    "    imputations=[]\n",
    "    with T.autograd.no_grad():\n",
    "        if args.air:\n",
    "            data=pd.read_csv('.../aaai/data/air/preprocess/airTest.csv',header=0)\n",
    "            mask=pd.read_csv('.../aaai/data/air/preprocess/airTestMask.csv',header=0)\n",
    "            data=data[['Date', 'Time', 'Month', 'PT08.S1(CO)', 'CO(GT)', 'NMHC(GT)','C6H6(GT)', 'PT08.S2(NMHC)', 'NOx(GT)', 'PT08.S3(NOx)', 'NO2(GT)','PT08.S4(NO2)', 'PT08.S5(O3)', 'T', 'RH', 'AH']]\n",
    "            del data['Time']\n",
    "            del data['Date']\n",
    "            del mask['Time']\n",
    "            del mask['Date']\n",
    "\n",
    "        if args.mimic:\n",
    "            data=pd.read_csv('.../aaai/data/mimic/preprocess/mimicTest.csv',header=0)\n",
    "            mask=pd.read_csv('.../aaai/data/mimic/preprocess/mimicTestMask.csv',header=0)\n",
    "            del data['subject_id']\n",
    "            del data['charttime']\n",
    "            del mask['subject_id']\n",
    "            del mask['charttime']\n",
    "            print(data.shape)\n",
    "            data=data[['ALBUMIN', 'ANION GAP','WBC', 'BANDS', 'BICARBONATE', 'BILIRUBIN', 'BUN',\n",
    "           'CHLORIDE', 'CREATININE', 'GLUCOSE', 'HEMATOCRIT', 'HEMOGLOBIN', 'INR',\n",
    "           'LACTATE', 'PaCO2', 'PLATELET', 'POTASSIUM', 'PT', 'PTT', 'SODIUM'\n",
    "           ]]\n",
    "\n",
    "        \n",
    "        data = T.as_tensor(data.values.astype(float), dtype=T.float32)\n",
    "        data=data.view(int(data.shape[0]/args.seq_len), args.seq_len, data.shape[1])\n",
    "        \n",
    "        mask = T.as_tensor(mask.values.astype(float), dtype=T.float32)\n",
    "        mask=mask.view(int(mask.shape[0]/args.seq_len), args.seq_len, mask.shape[1])\n",
    "        \n",
    "        loss={}\n",
    "\n",
    "        decay=mask[:,:,1]\n",
    "        rdecay=mask[:,:,2]\n",
    "        mask=mask[:,:,0]\n",
    "\n",
    "\n",
    "        data=data.squeeze()\n",
    "        mask=mask.squeeze()\n",
    "        decay=decay.squeeze()\n",
    "        rdecay=rdecay.squeeze()\n",
    "        #print(data.shape)\n",
    "        #print(mask.shape)\n",
    "        #print(decay.shape)\n",
    "\n",
    "        #values to be predicted\n",
    "        y = data.clone().detach()\n",
    "        testMask = mask.clone().detach()\n",
    "        \n",
    "        y=y[:,:,2]\n",
    "       \n",
    "\n",
    "        #------------remove last 5 timestamps------------------\n",
    "        #print(data[0:10,8:,653])\n",
    "        for i in range(data.shape[0]):\n",
    "            #if(data[i,])\n",
    "            j=20\n",
    "            if(predWin==8):\n",
    "                k=16\n",
    "                decay[i,j-k:j]=T.tensor([0.5,1,1.5,2,2.5,3,3.5,4,4.5,5,5.5,6,6.5,7,7.5,8])\n",
    "                rdecay[i,j-k:j]=T.tensor([8,7.5,7,6.5,6,5.5,5,4.5,4,3.5,3,2.5,2,1.5,1,0.5])\n",
    "            elif(predWin==7):\n",
    "                k=14\n",
    "                decay[i,j-k:j]=T.tensor([0.5,1,1.5,2,2.5,3,3.5,4,4.5,5,5.5,6,6.5,7])\n",
    "                rdecay[i,j-k:j]=T.tensor([7,6.5,6,5.5,5,4.5,4,3.5,3,2.5,2,1.5,1,0.5])*120\n",
    "            elif(predWin==6):\n",
    "                k=12\n",
    "                decay[i,j-k:j]=T.tensor([0.5,1,1.5,2,2.5,3,3.5,4,4.5,5,5.5,6])\n",
    "                rdecay[i,j-k:j]=T.tensor([6,5.5,5,4.5,4,3.5,3,2.5,2,1.5,1,0.5])\n",
    "            elif(predWin==5):\n",
    "                k=10\n",
    "                decay[i,j-k:j]=T.tensor([0.5,1,1.5,2,2.5,3,3.5,4,4.5,5])\n",
    "                rdecay[i,j-k:j]=T.tensor([5,4.5,4,3.5,3,2.5,2,1.5,1,0.5])\n",
    "\n",
    "            data[i,j-k:j,:]=0\n",
    "            mask[i,j-k:j]=0\n",
    "            y[i,0:j-k]=0\n",
    "            #print(sex.shape,age.shape)\n",
    "            #yOrig[i,0:j-k]=0\n",
    "            testMask[i,0:j-k]=0\n",
    "            \n",
    "            #print(data[i,j-k:j,0])\n",
    "            #print(mask[i,0:j-k,0])\n",
    "\n",
    "\n",
    "        ret_f, ret,disc = run_on_batch(model,discriminator,data,mask,decay,rdecay, args, optimizer=None,optimizer_d=None,epoch=None)#,bmi_norm)\n",
    "        print(\"Input\",data.shape)\n",
    "        print(data[0,:,2])\n",
    "        print(\"Reverse\",ret['imputations'][0,:])\n",
    "        print(\"ForwardOnly\",ret_f['imputations'][0,:])\n",
    "        print(\"Original\",y.shape)\n",
    "        print(y[0,:])\n",
    "        print(\"Mask\",testMask.shape)\n",
    "        print(testMask[0,:])\n",
    "        RLoss=RLoss+ret['loss']\n",
    "        FLoss=FLoss+ret_f['loss']\n",
    "        testMask=testMask.cuda()\n",
    "        y=y.cuda()\n",
    "        outputBMI=ret['imputations'] * testMask\n",
    "        outputBMIF=ret_f['imputations'] * testMask\n",
    "        mseLoss=mseLoss+ (torch.sum(torch.abs(outputBMI-y)))/ (torch.sum(testMask) + 1e-5)\n",
    "        mseLossF=mseLossF+ (torch.sum(torch.abs(outputBMIF-y)))/ (torch.sum(testMask) + 1e-5)\n",
    "#         print(\"RMSELoss Revrese: \",mseLoss)\n",
    "#         print(\"RMSELoss Forward: \",mseLossF)\n",
    "        outBmi, outBmiF,inBmi = plotBmi(outputBMI, outputBMIF, y, testMask)\n",
    "        oBmi.extend(outBmi)\n",
    "        oBmiF.extend(outBmiF)\n",
    "        iBmi.extend(inBmi)\n",
    "\n",
    "        \n",
    "        RLoss = RLoss\n",
    "        mseLoss = mseLoss\n",
    "        mseLossF = mseLossF\n",
    "    #print(\"===================================\")\n",
    "    oBmi=np.asarray(oBmi)\n",
    "    iBmi=np.asarray(iBmi)\n",
    "    loss = (oBmi - iBmi)\n",
    "    loss=np.asarray([abs(number) for number in loss])\n",
    "    variance = sum([((x - mseLoss) ** 2) for x in loss]) / len(loss) \n",
    "    res = variance ** 0.5\n",
    "    ci=1.96*(res/(math.sqrt(len(loss))))\n",
    "\n",
    "    #print(\"Val R Loss:\",RLoss)\n",
    "    print(\"CI\",ci)\n",
    "    print(\"MAE Loss Reverse:\",mseLoss)\n",
    "    #print(\"MAE Loss Forward:\",mseLossF)\n",
    "    #print(outputBMI)\n",
    "    return oBmi,oBmiF,iBmi\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputation_test(args, model,discriminator,missingRate):\n",
    "    model.eval()\n",
    "    \n",
    "    RLoss=0\n",
    "    FLoss=0\n",
    "    mseLoss=0\n",
    "    mseLossF=0\n",
    "    TBatches=0\n",
    "    oBmi=[]\n",
    "    oBmiF=[]\n",
    "    iBmi=[]\n",
    "    oAge=[]\n",
    "    oSex=[]\n",
    "    imputations=[]\n",
    "    samples=0\n",
    "    pids=0\n",
    "    with T.autograd.no_grad():\n",
    "        if args.air:\n",
    "            data=pd.read_csv('.../aaai/data/air/preprocess/airTest.csv',header=0)\n",
    "            mask=pd.read_csv('.../aaai/data/air/preprocess/airTestMask.csv',header=0)\n",
    "            data=data[['Date', 'Time', 'Month', 'PT08.S1(CO)', 'CO(GT)', 'NMHC(GT)','C6H6(GT)', 'PT08.S2(NMHC)', 'NOx(GT)', 'PT08.S3(NOx)', 'NO2(GT)','PT08.S4(NO2)', 'PT08.S5(O3)', 'T', 'RH', 'AH']]\n",
    "            del data['Time']\n",
    "            del data['Date']\n",
    "            del mask['Time']\n",
    "            del mask['Date']\n",
    "\n",
    "        if args.mimic:\n",
    "            data=pd.read_csv('.../aaai/data/mimic/preprocess/mimicTest.csv',header=0)\n",
    "            mask=pd.read_csv('.../aaai/data/mimic/preprocess/mimicTestMask.csv',header=0)\n",
    "            del data['subject_id']\n",
    "            del data['charttime']\n",
    "            del mask['subject_id']\n",
    "            del mask['charttime']\n",
    "            print(data.shape)\n",
    "            data=data[['ALBUMIN', 'ANION GAP','WBC', 'BANDS', 'BICARBONATE', 'BILIRUBIN', 'BUN',\n",
    "           'CHLORIDE', 'CREATININE', 'GLUCOSE', 'HEMATOCRIT', 'HEMOGLOBIN', 'INR',\n",
    "           'LACTATE', 'PaCO2', 'PLATELET', 'POTASSIUM', 'PT', 'PTT', 'SODIUM'\n",
    "           ]]\n",
    "\n",
    "        \n",
    "        data = T.as_tensor(data.values.astype(float), dtype=T.float32)\n",
    "        data=data.view(int(data.shape[0]/args.seq_len), args.seq_len, data.shape[1])\n",
    "        \n",
    "        mask = T.as_tensor(mask.values.astype(float), dtype=T.float32)\n",
    "        mask=mask.view(int(mask.shape[0]/args.seq_len), args.seq_len, mask.shape[1])\n",
    "        \n",
    "        loss={}\n",
    "\n",
    "        decay=mask[:,:,1]\n",
    "        rdecay=mask[:,:,2]\n",
    "        mask=mask[:,:,0]\n",
    "\n",
    "        data=data.squeeze()\n",
    "        mask=mask.squeeze()\n",
    "        decay=decay.squeeze()\n",
    "        rdecay=rdecay.squeeze()\n",
    "        #print(data.shape)\n",
    "        #print(mask.shape)\n",
    "        #print(decay.shape)\n",
    "\n",
    "        #values to be predicted\n",
    "        y = data.clone().detach()\n",
    "        testMask = mask.clone().detach()\n",
    "        y=y[:,:,2]\n",
    "\n",
    "        #------------remove last 5 timestamps------------------\n",
    "        #print(data[0:10,8:,653])\n",
    "        for i in range(data.shape[0]):\n",
    "            #if(data[i,])\n",
    "            j=20\n",
    "            k=16\n",
    "            #mask[i,:].loc[mask[i,:].query('value == 1').sample(frac=.1).index,'value'] = 0\n",
    "            idxs = torch.nonzero(mask[i,:] == 1)\n",
    "            #print(\"idxs\",list(idxs.size())[0])\n",
    "            #print(idxs)\n",
    "            samples=samples+list(idxs.size())[0]\n",
    "            if(missingRate==50):\n",
    "                if(list(idxs.size())[0]>4):\n",
    "                    idxs=random.sample(set(idxs),5)\n",
    "                    data[i,idxs[0],2]=0\n",
    "                    data[i,idxs[1],2]=0\n",
    "                    data[i,idxs[2],2]=0\n",
    "                    data[i,idxs[3],2]=0\n",
    "                    data[i,idxs[4],2]=0\n",
    "                    #print(mask[i,:])\n",
    "                    mask[i,idxs[0]]=0\n",
    "                    mask[i,idxs[1]]=0\n",
    "                    mask[i,idxs[2]]=0\n",
    "                    mask[i,idxs[3]]=0\n",
    "                    mask[i,idxs[4]]=0\n",
    "                    pids=pids + 5\n",
    "                    break;\n",
    "            if(missingRate>=40):\n",
    "                if(list(idxs.size())[0]>3):\n",
    "                    idxs=random.sample(set(idxs),4)\n",
    "                    data[i,idxs[0],2]=0\n",
    "                    data[i,idxs[1],2]=0\n",
    "                    data[i,idxs[2],2]=0\n",
    "                    data[i,idxs[3],2]=0\n",
    "                    #print(mask[i,:])\n",
    "                    mask[i,idxs[0]]=0\n",
    "                    mask[i,idxs[1]]=0\n",
    "                    mask[i,idxs[2]]=0\n",
    "                    mask[i,idxs[3]]=0\n",
    "                    pids=pids + 4\n",
    "                    break;\n",
    "            if(missingRate>=30):\n",
    "                if(list(idxs.size())[0]>2):\n",
    "                    idxs=random.sample(set(idxs),3)\n",
    "                    data[i,idxs[0],2]=0\n",
    "                    data[i,idxs[1],2]=0\n",
    "                    data[i,idxs[2],2]=0\n",
    "                    #print(mask[i,:])\n",
    "                    mask[i,idxs[0]]=0\n",
    "                    mask[i,idxs[1]]=0\n",
    "                    mask[i,idxs[2]]=0\n",
    "                    pids=pids + 3\n",
    "                    break;\n",
    "            if(missingRate>=20):\n",
    "                if(list(idxs.size())[0]>1):\n",
    "                    idxs=random.sample(set(idxs),2)\n",
    "                    data[i,idxs[0],2]=0\n",
    "                    data[i,idxs[1],2]=0\n",
    "                    #print(mask[i,:])\n",
    "                    mask[i,idxs[0]]=0\n",
    "                    mask[i,idxs[1]]=0\n",
    "                    pids=pids + 2\n",
    "                    break;\n",
    "            if(missingRate>=10):\n",
    "                if(list(idxs.size())[0]>0):\n",
    "                    idxs=random.sample(set(idxs),1)\n",
    "                    data[i,idxs,2]=0\n",
    "                    mask[i,idxs]=0\n",
    "                    pids=pids + 1\n",
    "            #print(idxs)\n",
    "            #print(\"---------------\")\n",
    "            #remove values from last 50% of the sequence\n",
    "\n",
    "\n",
    "            #print(mask[i,:])\n",
    "            testMask[i,:]=testMask[i,:]-mask[i,:]\n",
    "            y[i,:]=y[i,:]*testMask[i,:]\n",
    "\n",
    "\n",
    "        #print(\"Input Data\",data.shape)\n",
    "        #print(\"Input Mask\",mask.shape)\n",
    "        ret_f,ret,disc = run_on_batch(model,discriminator,data,mask,decay,rdecay, args, optimizer=None,optimizer_d=None,epoch=None)#,bmi_norm)\n",
    "#             print(\"Input\",data.shape)\n",
    "#             print(data[0,:,316])\n",
    "#             print(\"Reverse\",ret['imputations'][0,:])\n",
    "#             print(\"ForwardOnly\",ret_f['imputations'][0,:])\n",
    "#             print(\"Original\",y.shape)\n",
    "#             print(y[0,:])\n",
    "        #print(\"Mask\",testMask.shape)\n",
    "        #print(testMask[0,:])\n",
    "        RLoss=RLoss+ret['loss']\n",
    "        FLoss=FLoss+ret_f['loss']\n",
    "        testMask=testMask.cuda()\n",
    "        y=y.cuda()\n",
    "        #print(\"Output\",ret['imputations'].shape)\n",
    "        #print(\"Output\",ret_f['imputations'].shape)\n",
    "        #print(\"Output mask\",testMask.shape)\n",
    "        outputBMI=ret['imputations'] * testMask\n",
    "        outputBMIF=ret_f['imputations'] * testMask\n",
    "        #print(\"outputBMI\",outputBMI.shape)\n",
    "        #print(outputBMI[0])\n",
    "        #print(\"outputBMIF\",outputBMIF.shape)\n",
    "        #print(outputBMIF[0])\n",
    "        mseLoss=mseLoss+ (torch.sum(torch.abs(outputBMI-y)))/ (torch.sum(testMask) + 1e-5)\n",
    "        mseLossF=mseLossF+ (torch.sum(torch.abs(outputBMIF-y)))/ (torch.sum(testMask) + 1e-5)\n",
    "#             print(\"RMSELoss Revrese: \",mseLoss)\n",
    "#             print(\"RMSELoss Forward: \",mseLossF)\n",
    "        outBmi, outBmiF,inBmi = plotBmi(outputBMI, outputBMIF, y, testMask)\n",
    "        oBmi.extend(outBmi)\n",
    "        oBmiF.extend(outBmiF)\n",
    "        iBmi.extend(inBmi)\n",
    "        \n",
    "\n",
    "        RLoss = RLoss\n",
    "        mseLoss = mseLoss\n",
    "        mseLossF = mseLossF\n",
    "    #print(\"===================================\")\n",
    "    oBmi=np.asarray(oBmi)\n",
    "    iBmi=np.asarray(iBmi)\n",
    "    loss = (oBmi - iBmi)\n",
    "    loss=np.asarray([abs(number) for number in loss])\n",
    "    variance = sum([((x - mseLoss) ** 2) for x in loss]) / len(loss) \n",
    "    res = variance ** 0.5\n",
    "    ci=1.96*(res/(math.sqrt(len(loss))))\n",
    "\n",
    "    #print(\"Val R Loss:\",RLoss)\n",
    "    print(\"CI\",ci)\n",
    "    print(\"MAE Loss Reverse:\",mseLoss)\n",
    "    #print(\"MSE Loss Forward:\",mseLossF)\n",
    "    #print(outputBMI)\n",
    "    return oBmi,oBmiF,iBmi\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotBmi(outBmi,outBmiF, inBmi, testMask):\n",
    "    \n",
    "    outBmi = outBmi.cpu().detach().numpy()\n",
    "    outBmiF = outBmiF.cpu().detach().numpy()\n",
    "    inBmi = inBmi.cpu().detach().numpy()\n",
    "#     outAge = outAge.cpu().detach().numpy()\n",
    "#     outSex = outSex.cpu().detach().numpy()\n",
    "    testMask = testMask.cpu().detach().numpy()\n",
    "    \n",
    "   \n",
    "    outBmi=outBmi[np.nonzero(testMask)]\n",
    "    outBmiF=outBmiF[np.nonzero(testMask)]\n",
    "    inBmi=inBmi[np.nonzero(testMask)]\n",
    "#     outAge=outAge[np.nonzero(testMask)]\n",
    "#     outSex=outSex[np.nonzero(testMask)]\n",
    "    \n",
    "    return outBmi,outBmiF,inBmi#, outAge, outSex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evalFull(args, model, discriminator):\n",
    "    model.eval()\n",
    "    \n",
    "    RLoss=0\n",
    "    GLoss=0\n",
    "    DLoss=0\n",
    "    TBatches=0\n",
    "    oBmi=[]\n",
    "    iBmi=[]\n",
    "    oAge=[]\n",
    "    oSex=[]\n",
    "   \n",
    "    with T.autograd.no_grad():\n",
    "        if args.air:\n",
    "            data=pd.read_csv('.../aaai/data/air/preprocess/airVal.csv',header=0)\n",
    "            mask=pd.read_csv('.../aaai/data/air/preprocess/airValMask.csv',header=0)\n",
    "            data=data[['Date', 'Time', 'Month', 'PT08.S1(CO)', 'CO(GT)', 'NMHC(GT)','C6H6(GT)', 'PT08.S2(NMHC)', 'NOx(GT)', 'PT08.S3(NOx)', 'NO2(GT)','PT08.S4(NO2)', 'PT08.S5(O3)', 'T', 'RH', 'AH']]\n",
    "            del data['Time']\n",
    "            del data['Date']\n",
    "            del mask['Time']\n",
    "            del mask['Date']\n",
    "\n",
    "        if args.mimic:\n",
    "            data=pd.read_csv('.../aaai/data/mimic/preprocess/mimicVal.csv',header=0)\n",
    "            mask=pd.read_csv('.../aaai/data/mimic/preprocess/mimicValMask.csv',header=0)\n",
    "            del data['subject_id']\n",
    "            del data['charttime']\n",
    "            del mask['subject_id']\n",
    "            del mask['charttime']\n",
    "            print(data.shape)\n",
    "            data=data[['ALBUMIN', 'ANION GAP','WBC', 'BANDS', 'BICARBONATE', 'BILIRUBIN', 'BUN',\n",
    "           'CHLORIDE', 'CREATININE', 'GLUCOSE', 'HEMATOCRIT', 'HEMOGLOBIN', 'INR',\n",
    "           'LACTATE', 'PaCO2', 'PLATELET', 'POTASSIUM', 'PT', 'PTT', 'SODIUM'\n",
    "           ]]\n",
    "\n",
    "        \n",
    "        \n",
    "        data = T.as_tensor(data.values.astype(float), dtype=T.float32)\n",
    "        data=data.view(int(data.shape[0]/args.seq_len), args.seq_len, data.shape[1])\n",
    "        \n",
    "        mask = T.as_tensor(mask.values.astype(float), dtype=T.float32)\n",
    "        mask=mask.view(int(mask.shape[0]/args.seq_len), args.seq_len, mask.shape[1])\n",
    "\n",
    "        \n",
    "        loss={}\n",
    "\n",
    "        decay=mask[:,:,1]\n",
    "        rdecay=mask[:,:,2]\n",
    "        mask=mask[:,:,0]\n",
    "\n",
    "        data=data.squeeze()\n",
    "        mask=mask.squeeze()\n",
    "        decay=decay.squeeze()\n",
    "        rdecay=rdecay.squeeze()\n",
    "        #print(data.shape)\n",
    "        #print(mask.shape)\n",
    "        #print(decay.shape)\n",
    "\n",
    "\n",
    "        ret_f, ret, disc = run_on_batch(model,discriminator,data,mask,decay,rdecay, args, optimizer=None,optimizer_d=None,epoch=None)#,bmi_norm)\n",
    "        RLoss=RLoss+ret['loss']\n",
    "        GLoss=GLoss+disc['loss_g'].item()\n",
    "        DLoss=DLoss+disc['loss_d'].item()\n",
    "\n",
    "        RLoss = RLoss\n",
    "        GLoss=GLoss\n",
    "        DLoss=DLoss\n",
    "    #print(\"===================================\")\n",
    "    print(\"Val R Loss:\",RLoss)\n",
    "    print(\"Val G Loss:\",GLoss)\n",
    "    print(\"Val D Loss:\",DLoss)\n",
    "    #print(outputBMI)\n",
    "    return RLoss,GLoss,DLoss\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(args, model, discriminator):\n",
    "    ''' Run a single epoch\n",
    "    '''\n",
    "\n",
    "    trainLoss=[]\n",
    "    discLoss=[]\n",
    "    gLoss=[]\n",
    "    valLoss=[]\n",
    "    gValLoss=[]\n",
    "    discValLoss=[]\n",
    "    \n",
    "    #define optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 1e-3)\n",
    "    optimizer_d = optim.Adam(discriminator.parameters(), lr = 1e-3)\n",
    "    \n",
    "    # initialize the early_stopping object\n",
    "    early_stopping = EarlyStopping(patience=args.patience, verbose=True)\n",
    "    if args.resume_training:\n",
    "        checkpoint = T.load(save_path)\n",
    "        optimizer.load_state_dict(checkpoint['trainer'])\n",
    "        optimizer_d.load_state_dict(checkpoint['trainer_d'])\n",
    "        early_stopping(1.896514, model, discriminator, optimizer, optimizer_d, save_path)\n",
    "    \n",
    "    #for evrey epoch\n",
    "    for epoch in range(args.num_epochs):\n",
    "        model.train()\n",
    "    \n",
    "        #Running Losses\n",
    "        RLoss=0\n",
    "        GLoss=0\n",
    "        DLoss=0\n",
    "        TBatches=0  \n",
    "        print(\"=============EPOCH=================\")\n",
    "        \n",
    "        if args.air:\n",
    "            data=pd.read_csv('.../aaai/data/air/preprocess/airTrain.csv',header=0)\n",
    "            mask=pd.read_csv('.../aaai/data/air/preprocess/airTrainMask.csv',header=0)\n",
    "            data=data[['Date', 'Time', 'Month', 'PT08.S1(CO)', 'CO(GT)', 'NMHC(GT)','C6H6(GT)', 'PT08.S2(NMHC)', 'NOx(GT)', 'PT08.S3(NOx)', 'NO2(GT)','PT08.S4(NO2)', 'PT08.S5(O3)', 'T', 'RH', 'AH']]\n",
    "            #data=data[['Date', 'Time', 'Month', 'PT08.S1(CO)', 'NO2(GT)','CO(GT)', 'NMHC(GT)','C6H6(GT)', 'PT08.S2(NMHC)', 'NOx(GT)', 'PT08.S3(NOx)','PT08.S4(NO2)', 'PT08.S5(O3)', 'T', 'RH', 'AH']]\n",
    "            del data['Time']\n",
    "            del data['Date']\n",
    "            del mask['Time']\n",
    "            del mask['Date']\n",
    "\n",
    "        if args.mimic:\n",
    "            data=pd.read_csv('.../aaai/data/mimic/preprocess/mimicTrain.csv',header=0)\n",
    "            mask=pd.read_csv('.../aaai/data/mimic/preprocess/mimicTrainMask.csv',header=0)\n",
    "            del data['subject_id']\n",
    "            del data['charttime']\n",
    "            del mask['subject_id']\n",
    "            del mask['charttime']\n",
    "            print(data.shape)\n",
    "            data=data[['ALBUMIN', 'ANION GAP','WBC', 'BANDS', 'BICARBONATE', 'BILIRUBIN', 'BUN',\n",
    "           'CHLORIDE', 'CREATININE', 'GLUCOSE', 'HEMATOCRIT', 'HEMOGLOBIN', 'INR',\n",
    "           'LACTATE', 'PaCO2', 'PLATELET', 'POTASSIUM', 'PT', 'PTT', 'SODIUM'\n",
    "           ]]\n",
    "\n",
    "        \n",
    "        \n",
    "        data = T.as_tensor(data.values.astype(float), dtype=T.float32)\n",
    "        data=data.view(int(data.shape[0]/args.seq_len), args.seq_len, data.shape[1])\n",
    "        \n",
    "        mask = T.as_tensor(mask.values.astype(float), dtype=T.float32)\n",
    "        mask=mask.view(int(mask.shape[0]/args.seq_len), args.seq_len, mask.shape[1])\n",
    "        \n",
    "#         print(data.shape)\n",
    "#         print(mask.shape)\n",
    "        #print(decay.shape)\n",
    "\n",
    "        decay=mask[:,:,1]\n",
    "        rdecay=mask[:,:,2]\n",
    "        mask=mask[:,:,0]\n",
    "\n",
    "        data=data.squeeze()\n",
    "        mask=mask.squeeze()\n",
    "        decay=decay.squeeze()\n",
    "        rdecay=rdecay.squeeze()\n",
    "        \n",
    "#         print(data.shape)\n",
    "#         print(mask.shape)\n",
    "#         print(decay.shape)\n",
    "\n",
    "\n",
    "        ret_f, ret, disc = run_on_batch(model,discriminator,data,mask,decay,rdecay, args, optimizer,optimizer_d,epoch)#,bmi_norm)\n",
    "        RLoss=RLoss+ret['loss'].item()\n",
    "        GLoss=GLoss+disc['loss_g'].item()\n",
    "        DLoss=DLoss+disc['loss_d'].item()\n",
    "\n",
    "       \n",
    "        RLoss=RLoss\n",
    "        GLoss=GLoss\n",
    "        DLoss=DLoss\n",
    "        \n",
    "        print(\"EPOCH:\", epoch, \"loss_R:\", \"%.4f\"%RLoss, \"loss_G:\", \"%.4f\"%GLoss, \"loss_D:\", \"%.4f\"%DLoss)\n",
    "        \n",
    "        trainLoss.append(RLoss)\n",
    "        discLoss.append(DLoss)\n",
    "        gLoss.append(GLoss)\n",
    "\n",
    "        valid_loss,g_valloss,disc_loss = run_evalFull(args, model,discriminator)\n",
    "        \n",
    "        valLoss.append(valid_loss)\n",
    "        discValLoss.append(disc_loss)\n",
    "        gValLoss.append(g_valloss)\n",
    "        #plotBmi(outBmi , inBmi)\n",
    "\n",
    "        \n",
    "        #if epoch<1 or epoch >5:\n",
    "        if not (T.isnan(valid_loss)):\n",
    "            early_stopping(valid_loss, model, discriminator, optimizer, optimizer_d, save_path)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "        #plot_grad_flow(model['e'].named_parameters())\n",
    "        #plot_grad_flow(model['g'].named_parameters())\n",
    "        #plot_grad_flow(model['d'].named_parameters())\n",
    "    return trainLoss,discLoss,gLoss, valLoss,discValLoss,gValLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(args):\n",
    "    \n",
    "    train_on_gpu = T.cuda.is_available()\n",
    "    if train_on_gpu:\n",
    "        print('Training on GPU.')\n",
    "    else:\n",
    "        print('No GPU available, training on CPU.')\n",
    "        \n",
    "    model = BGAN(args)\n",
    "    discriminator=BGAN_D()\n",
    "    \n",
    "    #print(\"discriminator\",discriminator)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        discriminator=discriminator.cuda()\n",
    "\n",
    "    if args.resume_training:\n",
    "        checkpoint = T.load(save_path)\n",
    "        model.load_state_dict(checkpoint['model'])\n",
    "        discriminator.load_state_dict(checkpoint['discriminator'])\n",
    "        #optimizer = optim.Adam(model.parameters(), lr = 1e-3)\n",
    "        #optimizer.load_state_dict(checkpoint['trainer'])\n",
    "        trainLoss,discLoss,gLoss, valLoss,discValLoss,gValLoss = run_epoch(args, model, discriminator) \n",
    "        #return trainLoss,discLoss,gLoss, valLoss,discValLoss,gValLoss\n",
    "    \n",
    "    elif args.train:\n",
    "        trainLoss,discLoss,gLoss, valLoss,discValLoss,gValLoss = run_epoch(args, model, discriminator) \n",
    "        #return trainLoss,discLoss,gLoss, valLoss,discValLoss,gValLoss\n",
    "        \n",
    "    elif args.evalImp:\n",
    "        #load Model\n",
    "        checkpoint = T.load(save_path)\n",
    "        model.load_state_dict(checkpoint['model'])\n",
    "        discriminator.load_state_dict(checkpoint['discriminator'])\n",
    "        optimizer = optim.Adam(model.parameters(), lr = 1e-3)\n",
    "        optimizer.load_state_dict(checkpoint['trainer'])\n",
    "        optimizer_d = optim.Adam(discriminator.parameters(), lr = 1e-3)\n",
    "        optimizer_d.load_state_dict(checkpoint['trainer_d'])\n",
    "        #RLoss,GLoss,DLoss = run_evalFull(args, model, discriminator)\n",
    "        oBmi, oBmiF, iBmi, oAge,oSex = imputation_test(args, model,discriminator,args.missingRate)\n",
    "        \n",
    "    elif args.evalPred:\n",
    "        #load Model\n",
    "        checkpoint = T.load(save_path)\n",
    "        model.load_state_dict(checkpoint['model'])\n",
    "        discriminator.load_state_dict(checkpoint['discriminator'])\n",
    "        optimizer = optim.Adam(model.parameters(), lr = 1e-3)\n",
    "        optimizer.load_state_dict(checkpoint['trainer'])\n",
    "        optimizer_d = optim.Adam(discriminator.parameters(), lr = 1e-3)\n",
    "        optimizer_d.load_state_dict(checkpoint['trainer_d'])\n",
    "        #RLoss,GLoss,DLoss = run_evalFull(args, model, discriminator)\n",
    "        oBmi, oBmiF, iBmi, oAge,oSex = pred_test(args, model,discriminator,args.pred_len)\n",
    "        \n",
    "        #return oBmi, oBmiF, iBmi, oAge,oSex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU.\n",
      "Val R Loss: tensor(61.0351, device='cuda:0')\n",
      "MSE Loss Reverse: tensor(3.9483, device='cuda:0')\n",
      "MSE Loss Forward: tensor(1.9724, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#trainLoss,discLoss,gLoss, valLoss,discValLoss,gValLoss = run(ARGS)\n",
    "#RLoss,GLoss,DLoss = run(ARGS)\n",
    "#oBmi, oBmiF, iBmi, oAge, oSex = run(ARGS)\n",
    "\n",
    "run(ARGS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Atena] *",
   "language": "python",
   "name": "conda-env-Atena-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
