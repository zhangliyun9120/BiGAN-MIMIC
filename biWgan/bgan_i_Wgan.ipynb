{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from ugan_i_Wgan.ipynb\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import math\n",
    "import argparse\n",
    "\n",
    "import import_ipynb\n",
    "from ugan_i_Wgan import *\n",
    "from sklearn import metrics\n",
    "\n",
    "SEQ_LEN = 36\n",
    "RNN_HID_SIZE = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BGAN(nn.Module):\n",
    "    def __init__(self,args):\n",
    "        super(BGAN, self).__init__()\n",
    "        self.build(args)\n",
    "        \n",
    "\n",
    "    def build(self,args):\n",
    "        self.ugan_f = UGAN(args)\n",
    "        self.ugan_b = UGAN(args)\n",
    "\n",
    "    def forward(self, data, mask, decay,rdecay,args):\n",
    "        ret_f = self.ugan_f(data, mask, decay, args, 'forward')\n",
    "        \n",
    "        #print(\"=====================================REVERSE===================================================\")\n",
    "        ret_b = self.reverse(self.ugan_b(data, mask, rdecay, args, 'backward'))\n",
    "\n",
    "        #print(\"going to merge results\")\n",
    "        ret = self.merge_ret(ret_f, ret_b)\n",
    "\n",
    "        return ret_f,ret\n",
    "\n",
    "    def merge_ret(self, ret_f, ret_b):\n",
    "        loss_f = ret_f['loss']\n",
    "        loss_b = ret_b['loss']\n",
    "        loss_c = self.get_consistency_loss(ret_f['imputations'], ret_b['imputations'])\n",
    "        \n",
    "        #print(loss_f,loss_b,loss_c)\n",
    "        #print(\"Foward Imputation\",ret_f['imputations'][0,:])\n",
    "        #print(\"Backward Imputation\",ret_b['imputations'][0,:])\n",
    "        #print(\"Imputations\",ret_f['imputations'][0,:])\n",
    "        #print(\"Fwd Combinations\",ret_f['combinations'][0,:])\n",
    "        #print(\"Missing\",ret_f['missing'][0,:])\n",
    "        #print(\"Originals\",ret_f['originals'][0,:])\n",
    "        \n",
    "        #print(\"Imputations\",ret_b['imputations'][0,:])\n",
    "        #print(\"Bwd Combinations\",ret_b['combinations'][0,:])\n",
    "        #print(\"Missing\",ret_b['missing'][0,:])\n",
    "        #print(\"Originals\",ret_b['originals'][0,:])\n",
    "\n",
    "        #loss = loss_f + loss_b + loss_c\n",
    "\n",
    "        imputations = ret_f['imputations'] * ret_f['combinations'] + ret_b['imputations'] * ret_b['combinations']\n",
    "        ret_b['imputations'] = imputations\n",
    "        #print(\"Final Imputations\",ret_b['imputations'][0,:])\n",
    "        #ret_b['originals'] = ret_b['originals'] * ret_b['missing']\n",
    "        #imputations = (ret_f['imputations'] + ret_b['imputations']) / 2\n",
    "        \n",
    "        x_loss = torch.sum(torch.abs(ret_b['originals'] - ret_b['imputations']) * ret_b['missing']) / (torch.sum(ret_b['missing']) + 1e-5)\n",
    "\n",
    "        ret_b['originals'] = ret_b['originals'] * ret_b['missing'] + ret_b['imputations'] * (1-ret_b['missing'])\n",
    "        #print(\"Complement Vector\",ret_b['originals'][0,:])\n",
    "        #ret_b['loss'] = loss\n",
    "        ret_b['loss'] = x_loss+loss_c\n",
    "        #print(\"loss\",ret_b['loss'])\n",
    "        #ret_f['predictions'] = predictions\n",
    "        #ret_b['imputations'] = imputations\n",
    "\n",
    "        return ret_b\n",
    "\n",
    "    def get_consistency_loss(self, pred_f, pred_b):\n",
    "        loss = torch.pow(pred_f - pred_b, 2.0).mean()\n",
    "        return loss\n",
    "\n",
    "    def reverse(self, ret):\n",
    "        #print(\"in Reverse\")\n",
    "        def reverse_tensor(tensor_):\n",
    "            if tensor_.dim() <= 1:\n",
    "                #print(\"dim <= 1\")\n",
    "                return tensor_\n",
    "            #print(\"dim > 1\")\n",
    "            indices = range(tensor_.size()[1])[::-1]\n",
    "            indices = Variable(torch.LongTensor(indices), requires_grad = False)\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                indices = indices.cuda()\n",
    "\n",
    "            return tensor_.index_select(1, indices)\n",
    "\n",
    "        for key in ret:\n",
    "            ret[key] = reverse_tensor(ret[key])\n",
    "\n",
    "        return ret\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def run_on_batch(model,data,mask,decay,rdecay,args, optimizer,epoch):\n",
    "        ret_f,ret = model(data, mask, decay,rdecay,args)\n",
    "        \n",
    "#         disc = discriminator(ret['originals'], mask, args)\n",
    "#         print(\"BATCH LOSS\",ret['loss'])\n",
    "#         print(\"BATCH LOSS\",disc['loss_g'])\n",
    "#         print(\"BATCH LOSS\",disc['loss_d'])\n",
    "#         print(\"one batch done\")\n",
    "\n",
    "        if optimizer is not None:\n",
    "            #print(\"OPTIMIZE\")\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            ret['loss'].backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        return ret_f,ret"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Atena] *",
   "language": "python",
   "name": "conda-env-Atena-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
