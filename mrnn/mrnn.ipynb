{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "every-satisfaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import math\n",
    "import argparse\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "SEQ_LEN = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-exemption",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalDecay(nn.Module):\n",
    "    def __init__(self, input_size,RNN_HID_SIZE, diag = False):\n",
    "        super(TemporalDecay, self).__init__()\n",
    "        self.diag = diag\n",
    "        self.build(input_size,RNN_HID_SIZE)\n",
    "\n",
    "    def build(self, input_size, RNN_HID_SIZE):\n",
    "        self.W = Parameter(torch.Tensor(RNN_HID_SIZE, input_size))\n",
    "        self.b = Parameter(torch.Tensor(RNN_HID_SIZE))\n",
    "        \n",
    "        if self.diag == True:\n",
    "            assert(input_size == RNN_HID_SIZE)\n",
    "            m = torch.eye(input_size, input_size)\n",
    "            self.register_buffer('m', m)\n",
    "            \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.W.size(0))\n",
    "        self.W.data.uniform_(-stdv, stdv)\n",
    "        if self.b is not None:\n",
    "            self.b.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, d):\n",
    "        if self.diag == True:\n",
    "            gamma = F.relu(F.linear(d, self.W * Variable(self.m), self.b))\n",
    "        else:\n",
    "            gamma = F.relu(F.linear(d, self.W, self.b))\n",
    "        gamma = torch.exp(-gamma)\n",
    "        return gamma\n",
    "\n",
    "class MRNN(nn.Module):\n",
    "    def __init__(self,args):\n",
    "        super(MRNN, self).__init__()\n",
    "        if args.air:\n",
    "            self.RNN_HID_SIZE = 10\n",
    "            self.NFEATURES = 14\n",
    "            self.var=2\n",
    "        if args.mimic:\n",
    "            self.RNN_HID_SIZE = 10\n",
    "            self.NFEATURES = 20\n",
    "            self.var=2\n",
    "        if args.ehr:\n",
    "            self.RNN_HID_SIZE = 400\n",
    "            self.NFEATURES = 813\n",
    "            self.var=811\n",
    "        self.build()\n",
    "\n",
    "    def build(self):\n",
    "        self.rnn_cell = nn.LSTMCell(self.NFEATURES + 1, self.RNN_HID_SIZE)\n",
    "\n",
    "        #self.regression = nn.Linear(RNN_HID_SIZE, 35)\n",
    "        self.regression = nn.Linear(self.RNN_HID_SIZE*2, 1)\n",
    "        \n",
    "    def get_hidden(self, values, masks, deltas, args, direct):\n",
    "        \n",
    "        #deltas=deltas.unsqueeze(dim=2).repeat(1,1,self.NFEATURES)\n",
    "#         print(\"deltas\",deltas.shape)\n",
    "\n",
    "        hiddens = []\n",
    "\n",
    "        h = Variable(torch.zeros((values.size()[0], self.RNN_HID_SIZE)))\n",
    "        c = Variable(torch.zeros((values.size()[0], self.RNN_HID_SIZE)))\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            h, c = h.cuda(), c.cuda()\n",
    "            values, masks, deltas = values.cuda(), masks.cuda(), deltas.cuda()\n",
    "        if(direct==\"forward\"):\n",
    "            for t in range(SEQ_LEN):\n",
    "                hiddens.append(h)\n",
    "\n",
    "                x = values[:, t, :]\n",
    "                m = masks[:, t]\n",
    "                d = deltas[:, t]\n",
    "                \n",
    "#                 print(\"x\",x.shape)\n",
    "#                 print(\"m\",m.shape)\n",
    "#                 print(\"d\",d.shape)\n",
    "                \n",
    "                m=m.unsqueeze(dim=1)\n",
    "                d=d.unsqueeze(dim=1)\n",
    "\n",
    "                inputs = torch.cat([x, m, d], dim = 1)\n",
    "#                 print(\"inputs\",inputs.shape)\n",
    "\n",
    "                h, c = self.rnn_cell(inputs, (h, c))\n",
    "        elif(direct==\"backward\"):\n",
    "            #print(\"BACKWARD\")\n",
    "            for t in range(SEQ_LEN-1,-1,-1):\n",
    "                hiddens.append(h)\n",
    "\n",
    "                x = values[:, t, :]\n",
    "                m = masks[:, t]\n",
    "                d = deltas[:, t]\n",
    "                \n",
    "                m=m.unsqueeze(dim=1)\n",
    "                d=d.unsqueeze(dim=1)\n",
    "\n",
    "                inputs = torch.cat([x, m, d], dim = 1)\n",
    "\n",
    "                h, c = self.rnn_cell(inputs, (h, c))\n",
    "\n",
    "        return hiddens\n",
    "    \n",
    "    def forward(self, values, masks, decay,rdecay,args):\n",
    "        # Original sequence with 24 time steps\n",
    "        \n",
    "        x_loss = 0.0\n",
    "        #y_loss = 0.0\n",
    "\n",
    "        imputations = []\n",
    "        hidden_forward = self.get_hidden(values, masks, decay, args, direct=\"forward\")\n",
    "        hidden_backward = self.get_hidden(values, masks, rdecay, args, direct=\"backward\")[::-1]\n",
    "    \n",
    "#         print(\"hidden_forward\",hidden_forward[0].shape)\n",
    "#         print(\"hidden_backward\",hidden_backward[0].shape)\n",
    "        deltas=decay\n",
    "        \n",
    "        for t in range(SEQ_LEN):\n",
    "            #print(\"===============\",t,\"======================\")\n",
    "            x = values[:, t, :]\n",
    "            m = masks[:, t]\n",
    "            d = deltas[:, t]\n",
    "            #print(\"d\",d[:,0].unsqueeze(dim=1).size())\n",
    "            #print(\"d\",d[7,:])\n",
    "            #print(d[:,0])\n",
    "\n",
    "            hf = hidden_forward[t]\n",
    "            hb = hidden_backward[t]\n",
    "            h = torch.cat([hf, hb], dim = 1)\n",
    "#             print(\"h\",h.size())\n",
    "            x_h = self.regression(h)\n",
    "            #print(\"Regression output\",x_h[0,:])\n",
    "\n",
    "#             print(\"Output regression\",x_h.size())\n",
    "            #print(\"Mask\",m.size())\n",
    "\n",
    "\n",
    "            #x_loss += torch.sum(torch.abs(x[:,316] - x_h[:,0]) * m) / (torch.sum(m) + 1e-5)\n",
    "            x_loss += torch.sum(torch.abs(x[:,self.var] - x_h[:,0]) * m) / (torch.sum(m) + 1e-5)\n",
    "\n",
    "            #print(\"X_loss\",x_loss)\n",
    "            m=m.unsqueeze(dim=1)\n",
    "\n",
    "            #imputations.append(x_c[:,316].unsqueeze(dim = 1))\n",
    "            imputations.append(x_h[:,0].unsqueeze(dim = 1))\n",
    "            #print(\"to be appended\",m.size())\n",
    "            #print(\"Imputations\",len(imputations))\n",
    "            #print(\"Imputations\",combFactor[0].size())\n",
    "\n",
    "        imputations = torch.cat(imputations, dim = 1)\n",
    "#         print(\"Final Imputations\",imputations.size())\n",
    "\n",
    "        return {'loss': x_loss / SEQ_LEN , 'imputations': imputations}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-portrait",
   "metadata": {},
   "outputs": [],
   "source": [
    " def run_on_batch(model,data,mask,decay,rdecay,args, optimizer):\n",
    "        ret = model(data, mask, decay,rdecay,args)\n",
    "        #print(\"BATCH LOSS\",ret['loss'])\n",
    "        #print(\"one batch done\")\n",
    "\n",
    "        if optimizer is not None:\n",
    "            #print(\"OPTIMIZE\")\n",
    "            optimizer.zero_grad()\n",
    "            ret['loss'].backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        return ret"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Atena] *",
   "language": "python",
   "name": "conda-env-Atena-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
